{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I scrape Indeed.com for data scientist salaries in cities across America and try to figure out whether or not a certain job post will pay above the median data scientist salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import everything I need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create list of cities I want to search Data Science jobs in in the format of what it looks like in the URL\n",
    "\n",
    "cities = ['New+York,+NY', 'Los+Angeles,+CA', 'Chicago,+IL', 'Houston,+TX', 'Philadelphia,+PA', 'Phoenix,+AZ',\n",
    "          'San+Antonio,+TX', 'San+Diego,+CA', 'Dallas,+TX', 'San+Jose,+CA', 'Austin,+TX', 'Jacksonville,+FL',\n",
    "          'Steamtteaman+Francisco,+CA', 'Indianapolis,+IN', 'Columbus,+OH', 'Fort+Worth,+TX', 'Charlotte,+NC', 'Seattle,+WA',\n",
    "          'Denver,+CO', 'El+Paso,+TX', 'Detroit,+MI', 'Washington,+DC', 'Boston,+MA', 'Memphis,+TN', 'Nashville,+TN', \n",
    "          'Portland,+OR', 'Oklahoma+City,+OK', 'Baltimore,+MD', 'Atlanta,+GA', 'Pittsburgh,+PA', 'Palo+Alto,+CA',\n",
    "          'Mountain+View,+CA', 'Cupertino,+CA', 'Cambridge,+MA', 'Miami,+FL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I use BeautifulSoup to scrape Indeed. I take the job title, company name, location, summary and salary (if there is one listed). I'm going to find the median of all the jobs that *do* have a listed salary and then build a machine learning classifier to try to predict whether or not all of the *other* job posts will pay above the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=New+York,+NY&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Los+Angeles,+CA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Chicago,+IL&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Houston,+TX&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Philadelphia,+PA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Phoenix,+AZ&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=San+Antonio,+TX&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=San+Diego,+CA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Dallas,+TX&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=San+Jose,+CA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Austin,+TX&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Jacksonville,+FL&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Steamtteaman+Francisco,+CA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Indianapolis,+IN&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Columbus,+OH&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Fort+Worth,+TX&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Charlotte,+NC&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Seattle,+WA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Denver,+CO&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=El+Paso,+TX&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Detroit,+MI&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Washington,+DC&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Boston,+MA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Memphis,+TN&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Nashville,+TN&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Portland,+OR&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Oklahoma+City,+OK&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Baltimore,+MD&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Atlanta,+GA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Pittsburgh,+PA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Palo+Alto,+CA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Mountain+View,+CA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Cupertino,+CA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Cambridge,+MA&fromage=any&limit=250&sort=&psf=advsrch\n",
      "https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=Miami,+FL&fromage=any&limit=250&sort=&psf=advsrch\n"
     ]
    }
   ],
   "source": [
    "# Scrape\n",
    "\n",
    "df = pd.DataFrame(columns=[\"title\",\"company\", \"location\",\"summary\", \"salary\"])\n",
    "p1 = \"https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=fulltime&st=&salary=$70,000%2B&radius=25&l=\"\n",
    "p2 = \"&fromage=any&limit=250&sort=&psf=advsrch\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in cities:\n",
    "    url = p1 + j + p2 \n",
    "    html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser', from_encoding=\"utf-8\")\n",
    "    print url\n",
    "\n",
    "    title = []\n",
    "    comp = []\n",
    "    loc = []\n",
    "    loc_code = []\n",
    "    sal = []\n",
    "    desc = []\n",
    "\n",
    "    for i in soup.find_all(name='div', attrs={'class':' row result'}):\n",
    "        title.append(i.find(name='h2').text)\n",
    "        comp.append(i.find(name='span', attrs={'class':'company'}).text)\n",
    "        loc.append(i.find(name='span', attrs={'class':'location'}).text)\n",
    "        loc_code.append(count)\n",
    "        try:\n",
    "            sal.append(i.find(name='nobr').text)\n",
    "        except:\n",
    "            sal.append(None)\n",
    "        desc.append(i.find(name='span', attrs={'class':'summary'}).text)\n",
    "\n",
    "    title = map(lambda s: s.strip(), title)\n",
    "    comp = map(lambda s: s.strip(), comp)\n",
    "    loc = map(lambda s: s.strip(), loc)\n",
    "    desc = map(lambda s: s.strip(), desc)\n",
    "\n",
    "    jobs = pd.DataFrame(columns=[\"title\",\"company\", \"location\", \"location_code\", \"summary\", \"salary\"])\n",
    "    jobs.title = title\n",
    "    jobs.company = comp\n",
    "    jobs.salary = sal\n",
    "    jobs.location = loc\n",
    "    jobs.location_code = loc_code\n",
    "    jobs.summary = desc\n",
    "    \n",
    "    # Append df of jobs in each city to an overall all jobs df\n",
    "\n",
    "    df = df.append(jobs)\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2437, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, I was able to get 2,437 job posts. Now let's see how many of them have salaries missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company             0\n",
       "location            0\n",
       "location_code       0\n",
       "salary           2316\n",
       "summary             0\n",
       "title               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, 2,316 missing salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notnull = df[df.salary.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to clean up the salary figure and only take the lower end of the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = notnull[(~notnull.salary.str.contains('hour')) & (~notnull.salary.str.contains('month'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/generic.py:2701: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df2.salary = df2.salary.apply(lambda x: x.replace(' a year',''))\n",
    "df2.salary = df2.salary.apply(lambda x: x.replace('$',''))\n",
    "df2.salary = df2.salary.apply(lambda x: x.replace(',',''))\n",
    "df2.salary = df2.salary.apply(lambda x: x.split('-')[0])\n",
    "df2.salary = df2.salary.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, again. I only have 107 salaries for 2400 job posts. But, we shall continue. Let's find the median. And create a binary target: 1 if above, 0 if equal or below the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med = df2.salary.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>location_code</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oliver James Associates</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Identifies and develops data sources to solve ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Venturi Ltd</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Data Scientist, FinTech, Python, R, Machine Le...</td>\n",
       "      <td>Data Scientist ( FinTech / Python / R / Machin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Selby Jennings</td>\n",
       "      <td>New York, NY 10167 (Midtown area)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Mentored junior data scientists. Data Scientis...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Selby Jennings</td>\n",
       "      <td>New York, NY 10167 (Midtown area)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Data Scientist | New York, NY. A pioneering In...</td>\n",
       "      <td>Data Scientist | Investment Research</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Beeswax</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>A minimum of 5 years experience in Machine lea...</td>\n",
       "      <td>Director / VP Data Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company                           location  location_code  \\\n",
       "0   Oliver James Associates                       New York, NY            0.0   \n",
       "22              Venturi Ltd                       New York, NY            0.0   \n",
       "36           Selby Jennings  New York, NY 10167 (Midtown area)            0.0   \n",
       "53           Selby Jennings  New York, NY 10167 (Midtown area)            0.0   \n",
       "65                  Beeswax                       New York, NY            0.0   \n",
       "\n",
       "      salary                                            summary  \\\n",
       "0    90000.0  Identifies and develops data sources to solve ...   \n",
       "22  200000.0  Data Scientist, FinTech, Python, R, Machine Le...   \n",
       "36  150000.0  Mentored junior data scientists. Data Scientis...   \n",
       "53  160000.0  Data Scientist | New York, NY. A pioneering In...   \n",
       "65  130000.0  A minimum of 5 years experience in Machine lea...   \n",
       "\n",
       "                                                title  target  \n",
       "0                                      Data Scientist       0  \n",
       "22  Data Scientist ( FinTech / Python / R / Machin...       1  \n",
       "36                                     Data Scientist       1  \n",
       "53               Data Scientist | Investment Research       1  \n",
       "65                         Director / VP Data Science       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['target'] = np.where(df2.salary > med, 1, 0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to save this data to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.to_csv('df2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>location_code</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oliver James Associates</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Identifies and develops data sources to solve ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Venturi Ltd</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Data Scientist, FinTech, Python, R, Machine Le...</td>\n",
       "      <td>Data Scientist ( FinTech / Python / R / Machin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Selby Jennings</td>\n",
       "      <td>New York, NY 10167 (Midtown area)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Mentored junior data scientists. Data Scientis...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Selby Jennings</td>\n",
       "      <td>New York, NY 10167 (Midtown area)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Data Scientist | New York, NY. A pioneering In...</td>\n",
       "      <td>Data Scientist | Investment Research</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>Beeswax</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>A minimum of 5 years experience in Machine lea...</td>\n",
       "      <td>Director / VP Data Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  company                           location  \\\n",
       "0           0  Oliver James Associates                       New York, NY   \n",
       "1          22              Venturi Ltd                       New York, NY   \n",
       "2          36           Selby Jennings  New York, NY 10167 (Midtown area)   \n",
       "3          53           Selby Jennings  New York, NY 10167 (Midtown area)   \n",
       "4          65                  Beeswax                       New York, NY   \n",
       "\n",
       "   location_code    salary                                            summary  \\\n",
       "0            0.0   90000.0  Identifies and develops data sources to solve ...   \n",
       "1            0.0  200000.0  Data Scientist, FinTech, Python, R, Machine Le...   \n",
       "2            0.0  150000.0  Mentored junior data scientists. Data Scientis...   \n",
       "3            0.0  160000.0  Data Scientist | New York, NY. A pioneering In...   \n",
       "4            0.0  130000.0  A minimum of 5 years experience in Machine lea...   \n",
       "\n",
       "                                               title  target  \n",
       "0                                     Data Scientist       0  \n",
       "1  Data Scientist ( FinTech / Python / R / Machin...       1  \n",
       "2                                     Data Scientist       1  \n",
       "3               Data Scientist | Investment Research       1  \n",
       "4                         Director / VP Data Science       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv('df2.csv')\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I'm just going to take a minute to step back and remember something regarding the baseline accuracy.\n",
    "The baseline accuracy is 50% because we are basing the classification on the median. Thus, by definition, 50% of the data is 1 and 50% is 0. Thus, if we classified everything as 1 or everything as 0, we would have an accuracy of 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classifier(X, y, clf):\n",
    "    \n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    acc = []\n",
    "    for i in range(50):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        acc.append(accuracy_score(y_pred, y_test))\n",
    "    \n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67636363636363628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "X = jobs.drop(['Unnamed: 0', 'company', 'location', 'salary', 'summary', 'title', 'target'], axis=1)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = jobs.target\n",
    "\n",
    "classifier(X, y, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run my classifier (in the case above, a Random Forest) 50x to adjust for fluctuations in accuracy, and I get about 67% accuracy. That's ok, but I can maybe do better. I'm going to some feature engineering and find more senior-level posts (if the job title has some senior-level word like lead or principal in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/pandas/core/indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/avinashtamby/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df2['senior'] = 0\n",
    "\n",
    "for i in range(len(df2.title)):\n",
    "    if ('Chief' in df2.title.iloc[i]):\n",
    "        df2['senior'].iloc[i] = 1\n",
    "        \n",
    "    elif ('Manager' in df2.title.iloc[i]):\n",
    "        df2['senior'].iloc[i] = 1\n",
    "        \n",
    "    elif ('Senior' in df2.title.iloc[i]):\n",
    "        df2['senior'].iloc[i] = 1\n",
    "        \n",
    "    elif ('Director' in df2.title.iloc[i]):\n",
    "        df2['senior'].iloc[i] = 1\n",
    "    \n",
    "    elif ('Sr' in df2.title.iloc[i]):\n",
    "        df2['senior'].iloc[i] = 1\n",
    "    \n",
    "    elif ('Lead' in df2.title.iloc[i]):\n",
    "        df2['senior'].iloc[i] = 1\n",
    "        \n",
    "    elif ('Principal' in df2.title.iloc[i]):\n",
    "        df2['senior'].iloc[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.to_csv('df2.csv', encoding='utf-8')\n",
    "jobs = pd.read_csv('df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68272727272727263"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = jobs.drop(['Unnamed: 0', 'company', 'location', 'salary', 'summary', 'title', 'target'], axis=1)\n",
    "\n",
    "classifier(X, y, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This adds some value, but the accuracy still isn't great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69636363636363641"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "tvec.fit(jobs.summary)\n",
    "tvec  = pd.DataFrame(tvec.transform(jobs.summary).todense(), columns=tvec.get_feature_names())\n",
    "\n",
    "classifier(tvec, y, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just barely better, but I'll take it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730909090909\n",
      "               importance\n",
      "location_code    0.052979\n",
      "team             0.042358\n",
      "analytics        0.032552\n",
      "scientists       0.031191\n",
      "data             0.030282\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.concat([X, tvec], axis=1)\n",
    "acc = []\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df3, y, test_size = 0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "print np.mean(acc)\n",
    "\n",
    "imp =  pd.DataFrame(clf.feature_importances_, index=df3.columns, columns=['importance'])\n",
    "imp.head()\n",
    "print imp.sort_values(['importance'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words and features above have the most predictive value when classifying jobs at above or below the median. Location makes sense, I imagine more expensive cities pay more. It's weird that 'data' is in there as these should all be data science jobs. But generally, it seems that quantitative aspects like 'analytics' and 'scientists' are pretty predictive.\n",
    "\n",
    "Next, I take a look at the confusion matrix, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0]\n",
      " [ 2  9]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        11\n",
      "          1       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.92      0.91      0.91        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(y_test, y_pred)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675454545455\n",
      "            importance\n",
      "learning      0.076278\n",
      "processing    0.070643\n",
      "analytics     0.057618\n",
      "data          0.054082\n",
      "developer     0.049816\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    clf = GradientBoostingClassifier()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df3, y, test_size = 0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc.append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "print np.mean(acc)\n",
    "\n",
    "imp =  pd.DataFrame(clf.feature_importances_, index=df3.columns, columns=['importance'])\n",
    "imp.head()\n",
    "print imp.sort_values(['importance'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, although running a GB classifier doesn't perform as well as the other classifiers I've tried, I think the word importances are pretty key here. 'Learning' was the most important feature, so I imagine employers really value people who are willing to learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
